# -*- coding: utf-8 -*-
"""tweet.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1b_20Yod5yvkr1lBPMRIivpe5m1RdLXtY

##Natural Language Processing with Disaster Tweets

***with basic RNN model & bidirectional RNN***

**Goal:**

Social media platforms, especially Twitter, have become critical for real-time communication during emergencies. With nearly everyone having a smartphone, people can instantly share what they're observing, making Twitter a valuable tool for organizations like disaster relief agencies and news outlets.

The goal is to build a deep learning machine learning model that can accurately predict which tweets are about actual disasters and which are not.

**Natural Language Process (NLP)**

A major challenge is distinguishing between genuine disaster reports and everyday language. For example, a tweet might use a word like "ABLAZE" metaphorically, which is obvious to a person but confusing for a machine. Thus, a NLP pre-process on the data will be in place before the training.

**Dataset**

The dataset contain 10,000 tweets with classified label.
*   Training Set Shape = (7613, 5)
*   Test Set Shape = (3263, 4)

Note: this dataset is from kaggle competition. Please see the detailed information [here](https://www.kaggle.com/competitions/nlp-getting-started/overview).
"""

from google.colab import drive
drive.mount('/content/gdrive')

!unzip /content/gdrive/MyDrive/Data_Science/NLP_tweet/nlp-getting-started.zip -d /content/tweet

!pip install keras-core --upgrade
!pip install -q keras-nlp --upgrade
import os
os.environ['KERAS_BACKEND'] = 'tensorflow'

import numpy as np
import pandas as pd
import tensorflow as tf
import keras_core as keras
import keras_nlp
from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

print("TensorFlow version:", tf.__version__)
print("KerasNLP version:", keras_nlp.__version__)

"""##Exploratory Data Analysis (EDA) & Data Cleaning Preprocess


For this project, a pre-built NLP library was used from Keras to streamline the data cleaning process for the tweets. This approach avoided time-consuming, manual data cleaning procedures on the large dataset. The Keras library efficiently handled basic text normalization, including standardizing capitalization, and managing punctuation. Following this, the TextVectorization package was used to convert the cleaned text into numerical vectors. To ensure consistent input for the model, padding was applied to these vectors so they all had the same length. While traditional, hard-coded cleaning methods might have offered further improvements, this automated process provided a robust and efficient way to prepare the data for training.
"""

# Define paths & load training dataset labels
data_dir = '/content/tweet'
df_train = pd.read_csv("/content/tweet/train.csv")
df_test = pd.read_csv("/content/tweet/test.csv")

print('Training Set Shape = {}'.format(df_train.shape))
print('Training Set Memory Usage = {:.2f} MB'.format(df_train.memory_usage().sum() / 1024**2))
print('Test Set Shape = {}'.format(df_test.shape))
print('Test Set Memory Usage = {:.2f} MB'.format(df_test.memory_usage().sum() / 1024**2))
df_train.head()

df_train["length"] = df_train["text"].apply(lambda x : len(x))
df_test["length"] = df_test["text"].apply(lambda x : len(x))

print("Train Length Stat")
print(df_train["length"].describe())
print()

print("Test Length Stat")
print(df_test["length"].describe())

# Add histograms for length distribution
plt.figure(figsize=(10, 5))

plt.subplot(1, 2, 1)
sns.histplot(df_train['length'], bins=50, kde=True, color='skyblue')
plt.title('Distribution of Tweet Lengths (Training Set)')
plt.xlabel('Tweet Length')
plt.ylabel('Frequency')

plt.subplot(1, 2, 2)
sns.histplot(df_test['length'], bins=50, kde=True, color='salmon')
plt.title('Distribution of Tweet Lengths (Test Set)')
plt.xlabel('Tweet Length')
plt.ylabel('Frequency')

plt.tight_layout()
plt.show()

import re
import itertools
import nltk
import math
nltk.download('stopwords')
from nltk.corpus import stopwords

!pip install contractions
!pip install tqdm

BATCH_SIZE = 32
NUM_TRAINING_EXAMPLES = df_train.shape[0]
TRAIN_SPLIT = 0.8
VAL_SPLIT = 0.2
STEPS_PER_EPOCH = int(NUM_TRAINING_EXAMPLES)*TRAIN_SPLIT // BATCH_SIZE

EPOCHS = 2
AUTO = tf.data.experimental.AUTOTUNE

#data split for basic distillBERT
from sklearn.model_selection import train_test_split

X_train, X_val, y_train, y_val = train_test_split(df_train["text"], df_train["target"], test_size=VAL_SPLIT, random_state=42)
X_test = df_test["text"]

##data split for basic RNN & bidirectional RNN
from sklearn.model_selection import train_test_split

RNN_X_train, RNN_X_val, RNN_y_train, RNN_y_val = train_test_split(df_train["text"], df_train["target"], test_size=VAL_SPLIT, random_state=42)
RNN_X_test = df_test["text"]

## The most comprehensive NLP way to clean text - too slow so keep it as reference

#Text Noises Reduction
# import contractions
# import re
# import nltk
# nltk.download("wordnet")
# from nltk.stem import WordNetLemmatizer
# from nltk.corpus import stopwords
# from tqdm.auto import tqdm
# from textblob import TextBlob

# # nltk.download('stopwords') # Downloaded in previous cell

# def preprocess_text(text):
#     """Applies text preprocessing steps."""
#     review = text
#     ##lower case
#     lower = review.lower()
#     ##expand contraction
#     contraction = " ".join([contractions.fix(expanded_word) for expanded_word in lower.split()])
#     ##remove numbers
#     num_off = re.sub(r'\d+', '', contraction)
#     ##remove punctuations & hash tag
#     # Fixed the regex for punctuation and added '#' to be removed
#     punctuation_off = re.sub(r'[^\w\s#]+', '', num_off)
#     # Removed '#' separately as the user mentioned removing hash tags
#     hashtag_off = punctuation_off.replace('#', '')
#     ## Take off the extra space
#     space_off = re.sub(' +', ' ', hashtag_off)
#     # spelling mistakes
#     spell = str(TextBlob(space_off).correct())
#     #stop words
#     stop_words = stopwords.words('english')
#     stop = ' '.join([word for word in spell.split() if word not in (stop_words)])

#     ##lemmatizer the sentance
#     lemmatizer = WordNetLemmatizer()
#     clean_text = lemmatizer.lemmatize(stop)

#     return clean_text

#processing the comprehensive NLP cleaning - too slow and keep as reference

# Example usage (optional, can be removed or commented out)
# Assuming df_train is already loaded and has a 'text' column
# from tqdm.auto import tqdm
# tqdm.pandas()

# RNN_X_train_clean = RNN_X_train.progress_apply(preprocess_text)
# display(RNN_X_train_clean.head())

# RNN_X_test_clean = RNN_X_test.progress_apply(preprocess_text)
# display(RNN_X_test_clean.head())

# RNN_X_val_clean = RNN_X_val.progress_apply(preprocess_text)
# display(RNN_X_val_clean.head())

# Tokenization and Pedding step by step - too slow and keep for reference

# from tensorflow.keras.layers import TextVectorization

# # Step 1: Explicit Tokenization (splitting into words)
# # Although preprocess_text handles some splitting, we'll make it explicit here
# # using simple splitting for demonstration. For a more robust approach,
# # a dedicated tokenizer like TweetTokenizer from NLTK could be used.
# X_train_tokens = [text.split() for text in RNN_X_train_clean]
# X_val_tokens = [text.split() for text in RNN_X_val_clean]
# X_test_tokens = [text.split() for text in RNN_X_text_clean]

# # Step 2: Vocabulary Creation and Padding using TextVectorization
# # This layer will build a vocabulary from the tokens and then pad the sequences
# VOCAB_SIZE = 10000
# SEQUENCE_LENGTH = 160

# vectorize_layer = TextVectorization(
#     max_tokens=VOCAB_SIZE,
#     output_sequence_length=SEQUENCE_LENGTH,
#     # We don't need to split again since we already tokenized
#     split=None
# )

# # Adapt the layer to build the vocabulary from the training tokens
# # Convert lists of tokens back to strings for adaptation, then apply padding
# vectorize_layer.adapt(X_train_tokens)

# # Apply the layer to your tokenized data to get padded integer sequences
# X_train_padded = vectorize_layer(X_train_tokens)
# X_val_padded = vectorize_layer(X_val_tokens)
# X_test_padded = vectorize_layer(X_test_tokens)


# print("Shape of X_train_padded:", X_train_padded.shape)
# print("Shape of X_val_padded:", X_val_padded.shape)
# print("Shape of X_test_padded:", X_test_padded.shape)

#using TEXTVectorization to vectorize the tweet & ped the length of vectors
from tensorflow.keras.layers import TextVectorization

# Define the vocabulary size and sequence length
VOCAB_SIZE = 10000
SEQUENCE_LENGTH = 160

# Create a TextVectorization layer for tokenization, vocabulary mapping, and padding/truncating
vectorize_layer = TextVectorization(
    max_tokens=VOCAB_SIZE,
    output_sequence_length=SEQUENCE_LENGTH) #basic NLP cleaning = lower_and_strip_punctuation
vectorize_layer.adapt(RNN_X_train)

# Apply the padding layer to your training, validation, and test data
X_train_padded_v2 = vectorize_layer(RNN_X_train)
X_val_padded_v2 = vectorize_layer(RNN_X_val)
X_test_padded_v2 = vectorize_layer(RNN_X_test)


print("Shape of X_train_padded_v2:", X_train_padded_v2.shape)
print("Shape of X_val_padded_v2:", X_val_padded_v2.shape)
print("Shape of X_test_padded_v2:", X_test_padded_v2.shape)

"""##Model Architecture - Basic RNN

SimpleRNNs are a possible model for this task because they are designed to process sequential data like text, allowing them to consider the order of words in a tweet. Their recurrent nature enables them to maintain an internal state that captures information from previous words, which is relevant for understanding the context of a tweet.

The basic RNN structure is a sequential model consisting of a few layers:


*   An Embedding layer which takes the sequences of integer token IDs and converts them into dense, fixed-size vectors (embeddings). This layer learns to represent words in a continuous vector space, where similar words have similar vectors.
*   A SimpleRNN layer that processes the sequence of embeddings one element at a time, maintaining a hidden state that captures information from the previous elements in the sequence. This layer is designed to capture sequential dependencies in the data.
*   A final Dense layer with a sigmoid activation function. This layer takes the output of the SimpleRNN layer and produces a single output value between 0 and 1, representing the probability of the tweet belonging to the positive class (a disaster tweet).

**Embedding**

Although I did not specific use any of more complex embedding method because the bi-directional model produced good result.However, I would like to note that one common approach is TF-IDF (Term Frequency-Inverse Document Frequency). If it is used, it could potentially improved the accuracy result.

TF-IDF works by assigning a weight to each word in a document based on its importance. It calculates this weight by considering two factors:

*   Term Frequency (TF): How often a word appears in a specific document.
*   Inverse Document Frequency (IDF): How rare or unique a word is across all documents in the corpus.

Multiplying these two values gives a word its TF-IDF score, where common words like "the" or "a" get a low score, while rare but important words receive a high score. This method effectively highlights the most relevant keywords in a document.
"""

##Training with basic simpleRNN model

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, SimpleRNN, Dense, Dropout

# Define the model
rnn_model = Sequential([
    # TextVectorization layer & vector padding can be added here for the future

    # Embedding layer to learn semantic representations within the text
    Embedding(input_dim=VOCAB_SIZE + 1, output_dim=64, input_length=SEQUENCE_LENGTH),
    # SimpleRNN layer
    SimpleRNN(units=64, return_sequences=False),
    # Dense layer with sigmoid activation for final classification
    Dense(1, activation='sigmoid')])

rnn_model.compile(optimizer='adam',
                  loss='binary_crossentropy',
                  metrics=['accuracy'])

rnn_model.summary()

history = rnn_model.fit(
    X_train_padded_v2,
    RNN_y_train,
    epochs=EPOCHS,
    batch_size=BATCH_SIZE,
    validation_data=(X_val_padded_v2, RNN_y_val))

"""##Results and Analysis

The basic RNN was failed to the task; **tuning of hyperparameters**, such as higher unit (128) and a different optimizer, none of helped. Thus, a **different structured model**, bi-directional LSTM model, was built as improvement. The primary reason the Bidirectional LSTM model performed much better than the SimpleRNN in this case is likely due to its ability to capture more complex and contextual patterns in the text.

Comparison of Model Performances:

|Model	| Accuracy	| Precision	| Recall|	F1
|-----|-----|-----|-----|-----|
SimpleRNN	|0.5739	|0.0000	|0.0000	|0.0000
Bidirectional LSTM	|0.8638	|0.7765	|0.7442	|0.7600

**Analysis:**

*SimpleRNN:* Unforunately, from the metrics and the confusion matrix, the SimpleRNN model performed very poorly. It essentially predicted class 0 for all instances. An accuracy of 0.5739 is slightly better than random guessing on an imbalanced dataset, but it failed to identify any positive cases (disaster tweets).

*Bidirectional LSTM:* The Bidirectional LSTM model shows significantly better performance across all metrics. It achieved an accuracy of nearly 80%, with good precision, recall, and F1 scores for identifying disaster tweets. The confusion matrix shows that it correctly identified a good number of true positives and true negatives, although there are still some false positives and false negatives.

**Why the Bidirectional LSTM is Better:**

*LSTM vs. SimpleRNN:* LSTM layers are better equipped to handle the vanishing gradient problem and learn long-term dependencies in sequences compared to SimpleRNNs.

*Bidirectional Processing:* By processing the text in both forward and backward directions, the Bidirectional LSTM can better considered the information from words that come both before and after the current word.

"""

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, SimpleRNN, Dense, Bidirectional, LSTM

# Redefine the model with LSTM bidirection model
rnn_model_improve = Sequential([
    # Embedding layer to learn semantic representations
    Embedding(input_dim=VOCAB_SIZE + 1, output_dim=64, input_length=SEQUENCE_LENGTH),
    # Bidirectional LSTM layer
    Bidirectional(LSTM(units=64, return_sequences=False)),
    # Dense layer with sigmoid activation for classification
    Dense(1, activation='sigmoid')])

rnn_model_improve.compile(optimizer='adam',
                  loss='binary_crossentropy',
                  metrics=['accuracy'])
rnn_model_improve.summary()

history_improve = rnn_model_improve.fit(
    X_train_padded_v2,
    RNN_y_train,
    epochs=EPOCHS,
    batch_size=BATCH_SIZE,
    validation_data=(X_val_padded_v2, RNN_y_val))

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd

# --- Evaluate SimpleRNN Model ---
print("Evaluating SimpleRNN Model...")
y_pred_prob_rnn = rnn_model.predict(X_val_padded_v2)
y_pred_rnn = (y_pred_prob_rnn > 0.5).astype("int32")

# Calculate metrics
accuracy_rnn = accuracy_score(RNN_y_val, y_pred_rnn)
precision_rnn = precision_score(RNN_y_val, y_pred_rnn)
recall_rnn = recall_score(RNN_y_val, y_pred_rnn)
f1_rnn = f1_score(RNN_y_val, y_pred_rnn)
cm_rnn = confusion_matrix(RNN_y_val, y_pred_rnn)

print(f"SimpleRNN Accuracy: {accuracy_rnn:.4f}")
print(f"SimpleRNN Precision: {precision_rnn:.4f}")
print(f"SimpleRNN Recall: {recall_rnn:.4f}")
print(f"SimpleRNN F1 Score: {f1_rnn:.4f}")

# Display confusion matrix
disp_rnn = ConfusionMatrixDisplay(confusion_matrix=cm_rnn, display_labels=[0, 1])
disp_rnn.plot(cmap=plt.cm.Blues)
plt.title('SimpleRNN Confusion Matrix')
plt.show()


# --- Evaluate Bidirectional LSTM Model ---
print("\nEvaluating Bidirectional LSTM Model...")
y_pred_prob_lstm_bi = rnn_model_improve.predict(X_val_padded_v2)
y_pred_lstm_bi = (y_pred_prob_lstm_bi > 0.5).astype("int32")

# Calculate metrics
accuracy_lstm_bi = accuracy_score(RNN_y_val, y_pred_lstm_bi)
precision_lstm_bi = precision_score(RNN_y_val, y_pred_lstm_bi)
recall_lstm_bi = recall_score(RNN_y_val, y_pred_lstm_bi)
f1_lstm_bi = f1_score(RNN_y_val, y_pred_lstm_bi)
cm_lstm_bi = confusion_matrix(RNN_y_val, y_pred_lstm_bi)

print(f"Bidirectional LSTM Accuracy: {accuracy_lstm_bi:.4f}")
print(f"Bidirectional LSTM Precision: {precision_lstm_bi:.4f}")
print(f"Bidirectional LSTM Recall: {recall_lstm_bi:.4f}")
print(f"Bidirectional LSTM F1 Score: {f1_lstm_bi:.4f}")

# Display confusion matrix
disp_lstm_bi = ConfusionMatrixDisplay(confusion_matrix=cm_lstm_bi, display_labels=[0, 1])
disp_lstm_bi.plot(cmap=plt.cm.Blues)
plt.title('Bidirectional LSTM Confusion Matrix')
plt.show()

# Predict probabilities on the test set using the improved model
y_pred_prob_test = rnn_model_improve.predict(X_test_padded_v2)

# Convert probabilities to binary predictions (0 or 1)
y_pred_test = (y_pred_prob_test > 0.5).astype("int32")

# Create a submission DataFrame
# Use the original test dataframe's 'id' column
submission_df = pd.DataFrame({'id': df_test['id'], 'target': y_pred_test.flatten()})
submission_df.to_csv('submission.csv', index=False)
display(submission_df.head())

print(submission_df.shape)

"""##Conclusion

Based on the results, the SimpleRNN model was ineffective for this task, failing to correctly classify positive instances. The Bidirectional LSTM, however, showed significant improvement, demonstrating the importance of capturing bidirectional context and long-term dependencies in text data for this classification problem. For future improvements, more comprehensive data cleaning methods like stemming or lemmatization could be explored, and different types of embeddings, such as TF-IDF or pre-trained embeddings, might further enhance the model's ability to understand the nuances of the text.

Reference

*   Information on TF-IDF : https://www.geeksforgeeks.org/machine-learning/understanding-tf-idf-term-frequency-inverse-document-frequency/
*   Kaggle Notebook with TF_IDF: https://www.kaggle.com/code/awguhst/disaster-tweets-tf-idf-log-reg
*   Bidirection LSTM : https://www.kaggle.com/code/njuspy/disaster-tweets-glove-bidirectional-lstm
"""